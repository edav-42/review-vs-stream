---
output: html_document
---

```{r setup, include=FALSE}
# this prevents package loading message from appearing in the rendered version of your problem set
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(openintro)
library(tidyverse)
library(mi)
library(redav)
```

# Data 

## Sources

As stated in Chapter [Proposal](proposal.Rmd), we have three major data sources:

1. Metacritic, for critic reviews
2. Rate Your Music (RYM), for user ratings
3. Spotify, for album streams/popularity

We first scrapped album ratings from [Metacritic](https://metacritic.com), a famous and reliable website that aggregates reviews and ratings for music albums. We scrapped the critic ratings for albums released between 2018 and 2022(inclusive) and concatenate them to one table.
We get 2275 records in total.
(Please see [metacritic.Rmd](data/metacritic.Rmd) for scraping and cleaning code)

Based on the albums and artist name we got from the Metacritic website, we collected the user rating of corresponding albums from [Rate Your Music (RYM)](https://rateyourmusic.com), which is the largest community-driven online music database. To be specific, we query each albums by its name and artist through a modified unofficial API [rymscraper](https://github.com/dbeley/rymscraper). (Please see [rym.ipynb](data/rym.ipynb) for querying and cleaning code)

For the user popularity of each album, we collect popularity from [Spotify official APIs](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-track). Since Spotify provides the popularity of each track in an album, we records the min, mean, median, and max popularity of all tracks in a album for each album. (Please see [spotify.Rmd](data/spotify.Rmd) for querying and cleaning code)

Additionally, from Spotify APIs, we also collect the features of all songs that appears in the album that we collected before. That is, we have a new table to save the duration, name, popularity, acousticness, danceability, energy, instrumentalness, key, liveness, loudness, mode, speechiness, tempo, time_signature and valence of each song/track.(Please see [spotify_tracks.Rmd](data/spotify_tracks.Rmd) for querying and cleaning code)

Because the raw data is not so clean and showing them directly would be a disaster, we prefer introduce the types of variables and other information of these data set during&after cleaning and transformation. :)

### Data collecting

Since data collecting and processing is especially important in our project, before moving on to the cleaning and transformation section, we would like to further explain the method and logic behind our data collecting.

First, **none of our data is from an existent file**; we have to scrape the data manually or use some APIs. And for every source, there are two ways to get the data:

1. Scrape a chart. All sources provide some chart webpages, e.g.,<https://rateyourmusic.com/charts/>. These charts are in a table HTML element, so we can easily scrape them to get a CSV file.
2. Search a database. There are existent official/unofficial APIs, or we can build some basic APIs, for all sources. These APIs enable us to get the information of an album through related information, like artist and album name.

Therefore, the first question is which way should we use to collect the data. There are also two approaches:

1. Get all data by **scrapping charts**. Then join the charts from different sources.
2. Get a base chart, then **search the databases** for every record in the base chart.

We adapted the second approach, because the join operations may lead to either too many missing values (outer join) or too few records (inner join). Also, Spotify doesn't provide enough charts data.
Therefore, we scrapped Metacritic charts as the base charts, and then search the records in the charts using RYM and Spotify APIs.

The Spotify APIs performed relatively well and are closed source, hence we we didn't touch them. However, the RYM unofficial APIs miss many values without modification. Therefore, we enhance the RYM APIs by a three-layer search:

1. First we transform the artist and album name to an URL, and search the album directly using the URL. Since an artist or an album may have many alternative names and may contain special characters, this search may return an empty result with a high probability.
2. If the first search fails, we then use the artist name to search their discography. Then we look through the discography and return the closest match to what we are looking for. This search almost always find the album except for some edge cases like it finds the wrong artist.
3. If the first two searches fail, we then directly search the database using string "artist - album". Among returned records, we get the closest match to what we are looking for. Since a search engine will always return some results even the database doesn't contain the record, this search hardly fails.

The original RYM APIs only perform the second-layer search. Also, we adjust the "get closest match" method to make it more tolerant to special characters.
Although this three-layer search almost found all albums, some of the results are wrong; we will explain the reasons in section [Missing value analysis](#missing-value-analysis).

## Cleaning / transformation

### Metacritic Data

As we can see from below, the raw data we scrapped from the [Metacritic](https://metacritic.com), it is not so clean. The data doesn't have proper column name and some columns are useless in the following analysis. And more importantly, the data type of all columns are characters. 

![](assets/mt1.png)

Thus, before analyzing, we did data cleaning to the Metacritic data set:

1. Delete useless columns: V6, V8, V9 are useless because of either containing duplicate data or having long text that is not helpful.
2. Rename left columns: according to the meaning of each row, we rename the columns as `Metacritic_Score`, `Rank`, `Album_Name`, `Singer`, `Release_Date`, `Description`, `User_Score`, `Release_Year`
3. Transform the data
  - Metacritic_Score & Rank: transform them from type char to type int for future analysis.
  - Singer: contains redundant characters "by ", e.g. "by Fiona Apple". Extract only the artist name, e.g. "Fiona Apple"
  - User_Score: transform is from type char to type float for future analysis.
  - Release_Date: it is originally in char type, e.g. "April 17, 2020". Transform it to R datetime type, e.g. 2020-04-17
  - id: for future usage(joining different dataframe)

```{r}
library(rvest)
url = "https://www.metacritic.com/browse/albums/score/metascore/year/filtered?view=condensed&year_selected=2020&sort=desc&page=0"
# sample = get_data_from_url(url)
```


After transformation and cleaning, the Metacritic data contains 2275 observations of 9 different variables.


| Variable Name    | Data Type | Meaning                     |
|------------------|-----------|-----------------------------|
| id               | int       | album id                    |
| Metacritic_Score | int       | critic rating on Metacritic |
| Rank             | int       | rank in release year        |
| Album_Name       | chr       | album name                  |
| Singer           | chr       | album artist                |
| Release_Date     | Datetime  | album release date          |
| Description      | chr       | album description           |
| User_Score       | num       | album user score            |
| Release_Year     | int       | album release year          |

### Rate Your Music

As we can see from the snapshot of the description of sample album of the raw data we collected from [Rate Your Music (RYM)](https://rateyourmusic.com), the data is messy. 

![](assets/rym1.png)

Before conducting merging, data need cleaning and transformation.

1. Delete useless columns: Type, Recorded are useless because they contain duplicate data.
2. New column: We found that `RYM Rating` is in charcter type and contains not only ratings but also number of people who rate the album. Therefore, we extract the number of ratings and create a new column named `Num_of_RYM_Ratings`
3. Transform the data
  - Released: it is originally in char type, e.g. "14 September 2018". Transform it to R datetime type, e.g. 2018-09-14
  - RYM Rating: Extract ratings from characters and change the data type to numerate.
  - id: for future usage(joining different dataframe)
  - reserve the left data and transform them in the future if needed.



After transformation and cleaning, the RYM data contains 2275 observations of 13 different variables.

| Variable Name      | Data Type | Meaning                            |
|--------------------|-----------|------------------------------------|
| id                 | int       | album id                           |
| RYM.Rating         | int       | user rating on RYM                 |
| Ranked             | chr       | rank in release year               |
| Name               | chr       | album name                         |
| Artist             | chr       | album artist                       |
| Released           | Datetime  | album release date                 |
| Descriptors        | chr       | album description                  |
| Track.listing      | chr       | tracks in album                    |
| Release_Year       | int       | album release year                 |
| Genres             | chr       | album genre                        |
| Language           | chr       | song language                      |
| Colorscheme        | chr       | album colorscheme                  |
| Num_of_RYM_Ratings | int       | number of users who rate the album |


### Spotify

The data we get from [Spotify official APIs](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-track) is quite clean. Thus we will directly introduce the variables.

The album data set contains 2275 observations of 6 different variables.

| Variable Name | Data Type | Meaning                                        |
|---------------|-----------|------------------------------------------------|
| id            | int       | album id                                       |
| avg_pop       | num       | average popularity of all tracks in this album |
| max_pop       | int       | max popularity among all tracks in this album  |
| min_pop       | int       | min popularity among all tracks in this album  |
| med_pop       | num       | median popularity of all tracks in this album  |
| n             | int       | number od tracks in this album                 |

The data set for tracks contains 26834 observations of 16 different variables.

| Variable Name    | Data Type | Meaning                     |
|------------------|-----------|-----------------------------|
| id               | int       | album id                    |
| track_id         | chr       | id for tracking             |
| duration_ms      | int       | duration of each song in ms |
| name             | chr       | name of song                |
| popularity       | int       | popularity                  |
| acousticness     | int       | acousticness                |
| danceability     | num       | danceability                |
| energy           | num       | energy                      |
| instrumentalness | num       | instrumentalness            |
| key              | int       | key                         |
| liveness         | num       | liveness                    |
| loudness         | num       | loudness                    |
| mode             | int       | mode                        |
| speechiness      | num       | speechiness                 |
| tempo            | num       | tempo                       |
| time_signature   | int       | time_signature              |
| valence          | num       | valence                     |

### Final Data Set

After cleaning data set from each website/API, we concatenate 3 album-level data set by `id`, which was generated during the query to API using function `tibble::rowid_to_column`.

The final album data set has 2275 observations of 20 variables.(For duplicate columns, we only conserve 1 column in the final data set)

The following picture is for a rough look. Please see [this](assets/df1.png) for a detailed look.

![](assets/df1.png)

Remember that we also have a track-level data set from Spotify. We will have exploratory data analysis based on it later.

## Missing value analysis

We first analyze the joint album-level data.

```{r}
data <- read.csv('data/data.csv')
```

```{r fig.width=10}
mi::missing_data.frame(data)
names(data) <- abbreviate(gsub("_", "", names(data)), minlength = 3)
plot_missing(data, percent = F)
```

As we can see, there are only few values missing. This is due to the "search" nature of our collecting method. We get the matched results from some search engines; since it is rare for search engines to return an empty list, and we relax the matching criteria, values are rarely missing.

Also, the missing patterns are very clear:

1. If we cannot find an album on Spotify, then the data on its tracks are all missing; this includes `avg_pop, max_pop, min_pop, med_pop, n`.
    - The missing albums on spotify are due to copyrights restrictions. For example, the band Belly removed their album "Dove" from Spotify. All of these albums can be searched on Spotify, but no tracks information are offered.
2. If an album gets no ratings on RYM, its `RYM_Rating` and `Num_of_RYM_Ratings` are both missing.
    - There are two albums we found on RYM but with no `RYM_Rating` and `Num_of_RYM_Ratings`:
        - "Get Up Sequences, Pt. 1" by The Go! Team. On RYM, the title of this album is "Get Up Sequences Part One", and the artist has another album called "Get Up Sequences Part Two" comming up. Since our algorithm doesn't know "1" is "One", it returned the wrong, unreleased album, which has no ratings.
        - "MOSS" by Maya Hawke. This is an internal error of RYM: the page of "MOSS" <https://rateyourmusic.com/release/album/maya-hawke/moss> leads to a wrong page which has no rating
3. If we cannot find an album on RYM, then the data offered by RYM is missing; this includes `RYM_Rating, Num_of_RYM_Ratings, Genres, Language, Tracks, Colorscheme, RYM_Rank`.
   - There is only one album we cannot find on RYM: "Pulse/Quartet" by Steve Reich.

However, **complete** data doesn't mean **correct** data.
There is no such thing as a free lunch.
The completeness of our data provided by the "search" nature of our data collecting method also raise the probability of returning a **wrong** data, when the data *should be missing*.

For example, we use the first album returned by the Spotify search API as our observation. However, if the album doesn't exist on Spotify, it may still return some related results. Then we collect the wrong data.
Such senarios are more often when using RYM API.
For example, "Halloween [Original 2018 Motion Picture Soundtrack]" by John Carpenter in the Metacritic chart is a 2018 soundtrack which is not included by RYM. However, this album has many older versions, so the RYM API returns an older version which is released in 1983.
Some other examples includes that the album in the Metacritic chart is a new live version which is not included by RYM, so the RYM API returns the studio version.

![](assets/2022-12-14-15-19-10.png)

Also, we are exploring the "art" world; artists are full of creative ideas to name themself and their albums. Therefore, there are relatively more edge cases where we will get the wrongly-matched data.

However, it is hard to consider all the edge cases and eliminate the wrong data. It is our next steps to reduce the error possibility.

Now we give a brief analysis of the missing values in the track-level data.

```{r}
tracks <- read.csv('data/spotify_tracks.csv')
names(tracks) <- abbreviate(gsub("_", "", names(tracks)), minlength = 3)
plot_missing(tracks, percent = F)
```

As we can see, since we are collecting the tracks information of our already collected albums, the basic information like name (`nam`) and popularity (`ppl`) has no missing values. However, there are 20 tracks that do not have audio features. And we can see that if one of the audio feature is missing, all other audio features of that track are also missing. Therefore, we can deduce that Spotify may not record the audio information for those tracks, or the APIs fail to get the audio features.
